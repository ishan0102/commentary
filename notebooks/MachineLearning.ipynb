{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reply_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1223752255846912000</td>\n",
       "      <td>fox corporation owner fox news trying bully ro...</td>\n",
       "      <td>-0.520000</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1223738389003952128</td>\n",
       "      <td>folk hear cornovirus deal news heck doctor rec...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1223748267609030659</td>\n",
       "      <td>news finally excited journey potential finding...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1223739174160928773</td>\n",
       "      <td>good news person investigation novel coronavir...</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1223737953291128837</td>\n",
       "      <td>two avid golfer promised whoever died first wo...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                              tweet  \\\n",
       "0  1223752255846912000  fox corporation owner fox news trying bully ro...   \n",
       "1  1223738389003952128  folk hear cornovirus deal news heck doctor rec...   \n",
       "2  1223748267609030659  news finally excited journey potential finding...   \n",
       "3  1223739174160928773  good news person investigation novel coronavir...   \n",
       "4  1223737953291128837  two avid golfer promised whoever died first wo...   \n",
       "\n",
       "   sentiment  reply_count  \n",
       "0  -0.520000          150  \n",
       "1  -0.200000           45  \n",
       "2   0.500000            6  \n",
       "3  -0.250000           12  \n",
       "4   0.166667           36  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/cleaned_tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['tweet'].values.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31142 unique words in the dataset.\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(corpus)\n",
    "print(f'There are {tfidf_matrix.shape[1]} unique words in the dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save TF-IDF transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "pickle.dump(tfidf, open('../server/models/tfidf_vectorizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample of some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abner', 'abnormality', 'abo', 'aboard', 'abolish', 'abolished',\n",
       "       'abolishing', 'abolition', 'abolitionist', 'abomination'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tfidf.get_feature_names_out()\n",
    "features[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show TF-IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31132</th>\n",
       "      <th>31133</th>\n",
       "      <th>31134</th>\n",
       "      <th>31135</th>\n",
       "      <th>31136</th>\n",
       "      <th>31137</th>\n",
       "      <th>31138</th>\n",
       "      <th>31139</th>\n",
       "      <th>31140</th>\n",
       "      <th>31141</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   31132  31133  31134  31135  31136  31137  31138  31139  31140  31141  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 31142 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_matrix.todense())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 100/100] END lambda=44.35734297683265, learning_rate=0.09092388838675165, max_depth=39, n_estimators=71;, score=-0.197 total time=  44.0s\n",
      "[CV 2/5; 100/100] END lambda=44.35734297683265, learning_rate=0.09092388838675165, max_depth=39, n_estimators=71;, score=-0.195 total time=  44.1s\n",
      "[CV 4/5; 100/100] END lambda=44.35734297683265, learning_rate=0.09092388838675165, max_depth=39, n_estimators=71;, score=-0.200 total time=  43.3s\n",
      "[CV 3/5; 100/100] END lambda=44.35734297683265, learning_rate=0.09092388838675165, max_depth=39, n_estimators=71;, score=-0.199 total time=  43.4s\n",
      "[CV 5/5; 100/100] END lambda=44.35734297683265, learning_rate=0.09092388838675165, max_depth=39, n_estimators=71;, score=-0.186 total time=  43.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, gamma=None,\n",
       "                                          gpu_id=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None, max_bin=None,\n",
       "                                          m...\n",
       "                   param_distributions={'lambda': <scipy.stats._distn_infrastructure.rv_frozen object at 0x75f2248e0>,\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x757f42cd0>,\n",
       "                                        'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x75f224640>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x75f224430>},\n",
       "                   scoring='neg_mean_squared_error', verbose=10)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create classifier\n",
    "clf = XGBRegressor()\n",
    "\n",
    "# Do grid search to tune hyperparameters\n",
    "param_dist = {\n",
    "    'n_estimators': st.randint(10, 100),\n",
    "    'learning_rate': st.uniform(0, 0.3),\n",
    "    'max_depth': st.randint(10, 50),\n",
    "    'lambda': st.expon(0, 10),\n",
    "}\n",
    "random_clf = RandomizedSearchCV(clf, param_distributions=param_dist, n_jobs=-1, n_iter=100, scoring='neg_mean_squared_error', cv=5, verbose=10)\n",
    "\n",
    "# train classifier\n",
    "random_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda': 16.83453883045462,\n",
       " 'learning_rate': 0.1435953623400067,\n",
       " 'max_depth': 14,\n",
       " 'n_estimators': 59}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END .................................., score=-0.193 total time=   2.5s\n",
      "[CV 2/5] END .................................., score=-0.191 total time=   2.5s\n",
      "[CV 3/5] END .................................., score=-0.195 total time=   2.7s\n",
      "[CV 4/5] END .................................., score=-0.196 total time=   2.6s\n",
      "[CV 5/5] END .................................., score=-0.180 total time=   2.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.144, max_bin=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=15, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=59,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None,\n",
       "                                    reg_alpha=None, reg_lambda=16.835, ...),\n",
       "             param_grid={}, scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBRegressor(\n",
    "    n_estimators=59,\n",
    "    learning_rate=0.144,\n",
    "    max_depth=15,\n",
    "    reg_lambda=16.835\n",
    ")\n",
    "\n",
    "grid_clf = GridSearchCV(clf, param_grid={}, scoring='neg_mean_squared_error', cv=5, verbose=5)\n",
    "grid_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19710004165135916"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid_clf.best_estimator_\n",
    "mean_squared_error(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open('../server/models/xgboost_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19710004165135916"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = open('../server/models/xgboost_model.pkl', 'rb')\n",
    "model = pickle.load(model)\n",
    "model = grid_clf.best_estimator_\n",
    "mean_squared_error(y_test, model.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4771c68c01a26e26c9fe4acdb07a7c2494acf4caaf8c8ebd1e57f3f9fd859a44"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
