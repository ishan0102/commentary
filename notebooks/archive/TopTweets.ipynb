{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Tweets\n",
    "In this notebook, we fetch the top 100 tweets from the top 1000 Twitter accounts with the most followers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get top accounts and drop any users that don't have many tweets ([thanks to this gist](https://gist.github.com/mbejda/9c3353780270e7298763))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['justinbieber',\n",
       " 'katyperry',\n",
       " 'rihanna',\n",
       " 'Cristiano',\n",
       " 'ladygaga',\n",
       " 'elonmusk',\n",
       " 'TheEllenShow',\n",
       " 'KimKardashian',\n",
       " 'selenagomez',\n",
       " 'jtimberlake']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/top_accounts.csv')\n",
    "df = df.dropna(subset=['tweet_count'])\n",
    "top_accounts = df[df.tweet_count >= 2500]['twitter_username'].to_list()\n",
    "top_accounts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through top accounts and get tweets with at least 50,000 likes and 1,000 replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 766/766 [22:09<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(top_accounts))):\n",
    "    # Fetch user\n",
    "    username = top_accounts[i]\n",
    "    \n",
    "    # Run the query\n",
    "    c = twint.Config()\n",
    "    c.Username = username\n",
    "    c.Pandas = True\n",
    "    c.Hide_output = True\n",
    "    c.Min_likes = 50000\n",
    "    c.Min_replies = 1000\n",
    "    twint.run.Search(c)\n",
    "\n",
    "    # Store results\n",
    "    tweets = twint.storage.panda.Tweets_df\n",
    "    if len(tweets) > 0:\n",
    "        tweets = tweets.head(100)\n",
    "        tweets = tweets[['id', 'tweet']]\n",
    "        tweets.to_csv(f'../data/tweets/{username}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate results into a single CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4237"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Concatenate all the tweets\n",
    "usernames = [os.path.basename(f).split('.')[0] for f in glob.glob('../data/tweets/*.csv')]\n",
    "tweets = pd.concat([pd.read_csv(f'../data/tweets/{username}.csv') for username in usernames])\n",
    "\n",
    "# Add a column for usernames\n",
    "tweet_counts = [len(pd.read_csv(f'../data/tweets/{username}.csv')) for username in usernames]\n",
    "users_col = []\n",
    "for name, ct in zip(usernames, tweet_counts):\n",
    "    for i in range(ct):\n",
    "        users_col.append(name)\n",
    "tweets.insert(0, 'username', users_col)\n",
    "\n",
    "# Save as CSV\n",
    "tweets.to_csv('../data/parent_tweets.csv', index=False)\n",
    "len(tweets)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4771c68c01a26e26c9fe4acdb07a7c2494acf4caaf8c8ebd1e57f3f9fd859a44"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
